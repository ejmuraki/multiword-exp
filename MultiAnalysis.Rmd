---
title: "Multiword Analyses"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(moments)
library(tm)#Function to remove strings
library(reshape2)#for data manipulation
library(nlme)#for ICC
library(multilevel)#for ICC
library(arsenal)#for dataframe comparisons
library(jtools)#for theme_apa function for plots
library(apaTables)#for APA format tables
```

```{r organize output}
#Create paths
path_in = "/Users/emiko/OneDrive - University of Calgary/1. Research/Research Projects/Active/Multiword Expressions/Data/multiword-exp/Input"

figures_out = "/Users/emiko/OneDrive - University of Calgary/1. Research/Research Projects/Active/Multiword Expressions/Data/multiword-exp/Figures"

```


```{r read data}
#Get all ratings in long format
ratings_all <- read_csv("Ratings_RawData.csv") 
#Reduce ratings to only included participants
ratings_include <- ratings_all %>% 
  filter(Filter == 1)
#Get participant exclusion data
ppt_exclusions <- read_csv(file = file.path(path_in, "Ppt_Exclusions.csv"))
#Get expression coding
expression_coding <- read_csv(file = file.path(path_in, "Multiword_expression_categories.csv"))
#Get data for ICC analysis
ratings_icc <- read_csv(file = file.path(path_in, "Ratings_ICC_02.03.2022.csv"))
#Get Brysbaert 2014 concreteness ratings
brysbaert_concreteness <- read_csv(file = file.path(path_in, "Brysbaert_Kuperman_Conc.csv")) %>% 
  dplyr::rename(Expression = Word)
#Get function words list
functions <- read_csv(file = file.path(path_in, "Function_words.csv"))
#Get summarized concreteness ratings for expressions
master_ratings <- read_csv("MultiwordExpression_Concreteness_Ratings.csv")

```

```{r describe participant exclusions}
#Get total number of participants by platform without exclusions
total_p <- ppt_exclusions %>% count(Platform)

#Get exclusion information 
exclusion_stats <- ppt_exclusions %>% 
  summarise(Exclude_Incomplete = sum(Incomplete > .67), Exclude_Thirty_Plus = sum(Thirty_plus == TRUE & Incomplete < .67), Exclude_Correlation = sum(Correlation < 0.2 & Thirty_plus == FALSE, na.rm = TRUE), Exclude_Correlation_NA = sum(is.na(Correlation) & Incomplete < .67 & Thirty_plus == FALSE))

#Get total number of exclusions
total_excludes <- exclusion_stats %>% 
  summarise(Total_Excluded = sum(Exclude_Incomplete, Exclude_Thirty_Plus, Exclude_Correlation, Exclude_Correlation_NA))

#Get total number of participants left in dataset
ppt_totals <-as.data.frame(table(ratings_include$Participant))

#Get total number of exclusions by platform
platform_excludes <- ppt_exclusions %>% 
  group_by(Platform) %>% 
  summarise(Exclude_Incomplete = sum(Incomplete > .67), Exclude_Thirty_Plus = sum(Thirty_plus == TRUE & Incomplete < .67), Exclude_Correlation = sum(Correlation < 0.2 & Thirty_plus == FALSE, na.rm = TRUE), Exclude_Correlation_NA = sum(is.na(Correlation) & Incomplete < .67 & Thirty_plus == FALSE))

#Get only participants with correlation calculated
ppt_correlations <- ppt_exclusions %>%
  dplyr::filter(Incomplete < .67 & Thirty_plus == FALSE) %>% 
  dplyr::select(Participant, Platform, Correlation) %>% 
  drop_na()

#Create histogram of correlations
ggplot(ppt_correlations, aes(x = Correlation)) + geom_histogram(aes(y = ..density..), bins = 50, colour = 1, fill = "grey") + geom_density(lwd = 0.5, colour = 4, fill = 4, alpha = 0.25) + geom_vline(xintercept = 0.2, color = "red", size = 1.25) + theme_apa() + labs(x = "Mean Participant Correlation to Control Items (n = 2,598)") 

```

```{r get count of observations and ratings}
#Get number of observations not including skipped responses (-99)
total_observations <- ratings_include %>% 
  dplyr::filter(Rating > 0) %>% 
  nrow()
  
#Get number of observations that are "I don't know"
total_unknown <- ratings_include %>% 
  dplyr::filter(Rating == 6) %>% 
  nrow()

#Get number of valid observations
total_valid <- ratings_include %>% 
  dplyr::filter(Rating >= 0 & Rating < 6) %>%
  nrow()

#Calculate mean number of observations
mean(master_ratings$N_Rate, na.rm = TRUE)
max(master_ratings$N_Rate, na.rm = TRUE)

```

```{r check reliability}
#Calculate ICC based on function from psychometric package but customized optimizer (see Brysbaert et al. 2019 for method description) 
#Run multilevel model with optimizer set to optim
attach(ratings_icc)
mod <- lme(Rating ~ 1, random = ~1 | Expression, na.action = na.omit, control = lmeControl(opt = "optim"))
detach(ratings_icc)
#Extract intercept variance
t0 <- as.numeric(VarCorr(mod)[1,1])
#Extract residual variance
sig2 <- as.numeric(VarCorr(mod)[2,1])
#Calculate ICC based on intercept and residual variance
icc1 <- t0/(t0 + sig2)
#Calculate mean ICC across all group ICCs
icc2 <- mean(GmeanRel(mod)$MeanRel)

#Compare items to Brysbaert norms
master_complete <- master_ratings %>% 
  filter(N_Rate >= 10)
validity <- inner_join(master_complete, brysbaert_concreteness, by = "Expression")
conc_corr <- cor(validity$Mean_C, validity$Conc.M)
```

```{r get descriptive statistics}
#Calculate descriptive stats on mean ratings
master_complete <- left_join(master_complete, expression_coding, by = "Expression")

descriptives <- master_complete %>% 
  summarize(mean = mean(Mean_C), median = median(Mean_C), sd = sd(Mean_C), skew = skewness(Mean_C), kurtosis = kurtosis(Mean_C))

group_descriptives <- master_complete %>% 
  group_by(Type) %>% 
  summarize(mean = round(mean(Mean_C), digits = 2), median = round(median(Mean_C), digits = 2), sd = round(sd(Mean_C), digits = 2), skew = skewness(Mean_C), kurtosis = kurtosis(Mean_C))

type_count <- master_complete %>% 
  count(Type)
```

```{r get individual word concreteness, warning=FALSE}
#Create column with no hyphens 
exp_nohyphen <- as.data.frame(gsub("-", " ", expression_coding$Expression))

#Add no hyphen columns to data
exp_data <- bind_cols(expression_coding, exp_nohyphen)

exp_data <- exp_data %>% 
  rename("Expression_nohyphen" = "gsub(\"-\", \" \", expression_coding$Expression)")

#Get length in words of longest expression
NumWords <- max(sapply(gregexpr("\\W+", exp_data$Expression_nohyphen), length))

#Separate words in columns into single columns
words <- exp_data %>% 
  separate(Expression_nohyphen, c("W1", "W2", "W3", "W4", "W5", "W6", "W7", "W8", "W9", "W10", "W11", "W12", "W13", "W14", "W15", "W16", "W17", "W18", "W19", "W20", "W21", "W22", "W23", "W24", "W25", "W26", "W27", "W28"), extra = "drop", remove = FALSE)

#Change to long format
words_long <- reshape2::melt(words, id.vars = c("Expression", "Type", "Expression_nohyphen"))

#Rename column in concreteness ratings
conc <- brysbaert_concreteness %>% 
  dplyr::select(Expression, Conc.M) %>% 
  dplyr::rename(value = Expression)

#Join existing concreteness ratings with long data
words_long <- left_join(words_long, conc, by = "value")

#Calculate mean, max and min concreteness for each expression
expression_bconc <- words_long %>% 
  dplyr::group_by(Expression) %>% 
  dplyr::summarize(Mean_BConc = mean(Conc.M, na.rm = TRUE), Min_BConc = min(Conc.M, na.rm = TRUE), Max_BConc = max(Conc.M, na.rm = TRUE)) %>% 
  dplyr::mutate_if(is.numeric, funs(ifelse(is.nan(.), NA, .))) %>% 
  dplyr::mutate_if(is.numeric, funs(ifelse(is.infinite(.), NA, .)))

#Combine with expression coding
expressions_analysis <- left_join(master_complete, expression_bconc, by = "Expression")

#Remove function words from data
expressions_nofunction <- as.data.frame(removeWords(exp_data$Expression_nohyphen, functions$Functions))

#Rename column
expressions_nofunction <- rename(expressions_nofunction, "Expression_noFun" = "removeWords(exp_data$Expression_nohyphen, functions$Functions)")

#Bind columns to original
expressions_nofunction_all <- bind_cols(exp_data, expressions_nofunction)

#Get length in words of longest expression
NumWords <- max(sapply(gregexpr("\\W+", expressions_nofunction_all$Expression_noFun), length))

#Separate words in columns into single columns
nofun_words <- expressions_nofunction_all %>% 
  separate(Expression_noFun, c("W1", "W2", "W3", "W4", "W5", "W6", "W7", "W8", "W9", "W10", "W11", "W12", "W13", "W14", "W15", "W16", "W17"), extra = "drop", remove = FALSE)

#Change to long format
nofun_words_long <- reshape2::melt(nofun_words, id.vars = c("Expression", "Type", "Expression_nohyphen", "Expression_noFun"))

#Join existing concreteness ratings with long data
nofun_words_long <- left_join(nofun_words_long, conc, by = "value")

#Calculate mean, max and min concreteness for each expression less function words
expression_bconc_nofun <- nofun_words_long %>% 
  dplyr::group_by(Expression) %>% 
  dplyr::summarize(Mean_BConc_F = mean(Conc.M, na.rm = TRUE), Min_BConc_F = min(Conc.M, na.rm = TRUE), Max_BConc_F = max(Conc.M, na.rm = TRUE)) %>% 
  dplyr::mutate_if(is.numeric, funs(ifelse(is.nan(.), NA, .))) %>% 
  dplyr::mutate_if(is.numeric, funs(ifelse(is.infinite(.), NA, .)))

#Combine with expression coding
expressions_analysis_nofun <- left_join(master_complete, expression_bconc_nofun, by = "Expression")

```

```{r plot rating distribution}
#Create labels for subplots
Type.labs <- c("Idiom/Fixed expression", "Compound noun", "Particle verb", "All Expressions")
names(Type.labs) <- c("Idiom/Fixed expression", "Compound noun", "Particle verb", "(all)")

#Create histogram of all items
ggplot(expressions_analysis, aes(x = Mean_C)) + geom_histogram(aes(y = ..density..), bins = 25, colour = 1, fill = "grey") + geom_density(lwd = 0.5, colour = 4, fill = 4, alpha = 0.25) + theme_apa() + labs(x = "Mean Concreteness") + facet_grid(. ~ Type, margins = TRUE, labeller = labeller(Type = Type.labs))

#Save file
ggsave(filename = file.path(figures_out, "Figure1_02.25.2022.png"), width = 8, height = 4)
```


```{r compare to concreteness of individual words in the expressions}
#Check overall correlations
cor(expressions_analysis$Mean_C, expressions_analysis$Mean_BConc, use = "complete.obs")
cor(expressions_analysis$Mean_C, expressions_analysis$Max_BConc, use = "complete.obs")
cor(expressions_analysis$Mean_C, expressions_analysis$Min_BConc, use = "complete.obs")

#Check correlations by group
expressions_analysis %>% 
  dplyr::select(Expression, Type, Mean_BConc, Max_BConc, Min_BConc, Mean_C) %>% 
  drop_na() %>% 
  dplyr::group_by(Type) %>% 
  dplyr::summarize(Corr_mean = round(cor(Mean_C, Mean_BConc), digits = 2), Corr_max = round(cor(Mean_C, Max_BConc), digits = 2), Corr_min = round(cor(Mean_C, Min_BConc), digits = 2))

#Get count by group
expressions_analysis %>% 
  dplyr::select(Expression, Type, Mean_BConc, Max_BConc, Min_BConc, Mean_C) %>% 
  drop_na() %>% 
  dplyr::group_by(Type) %>%
  count()

```

```{r plot relationships of individual words and full expression}
#Get data frame for plot and change to long format
conc_compare_plot <- expressions_analysis %>% 
  dplyr::select(Expression, Type, Mean_BConc, Max_BConc, Min_BConc, Mean_C) %>% 
  drop_na() %>% 
  pivot_longer(cols = c("Mean_BConc", "Max_BConc", "Min_BConc"), names_to = "Ind_Words", values_to = "Mean_Conc_Words")

#Create labels for subplots
Ind_Words.labs <- c("Maximum Concreteness", "Mean Concreteness", "Minimum Concreteness")
names(Ind_Words.labs) <- c("Max_BConc", "Mean_BConc", "Min_BConc")

Type.labs <- c("Idiom/Fixed expression", "Compound noun", "Particle verb")
names(Type.labs) <- c("Idiom/Fixed expression", "Compound noun", "Particle verb")

#Plot relationships
ggplot(conc_compare_plot, aes(Mean_C, Mean_Conc_Words)) + geom_point(size = 0.25, colour = "black", alpha = 0.15) + geom_smooth(method = lm, lwd = 1, colour = 4) + facet_grid(Ind_Words ~ Type, labeller = labeller(Ind_Words = Ind_Words.labs, Type = Type.labs)) + xlab ("Concreteness of Expression") + ylab("Concreteness of Individual Words") + theme(text = element_text(size = 20))

#Save file
ggsave(filename = file.path(figures_out, "Figure2_02.25.2022.png"), width = 12, height = 12)
```

```{r compare to concreteness of content words in the expressions}
#Check overall correlations
cor(expressions_analysis_nofun$Mean_C, expressions_analysis_nofun$Mean_BConc_F, use = "complete.obs")
cor(expressions_analysis_nofun$Mean_C, expressions_analysis_nofun$Max_BConc_F, use = "complete.obs")
cor(expressions_analysis_nofun$Mean_C, expressions_analysis_nofun$Min_BConc_F, use = "complete.obs")

#Check correlations by group
expressions_analysis_nofun %>% 
  dplyr::select(Expression, Type, Mean_BConc_F, Max_BConc_F, Min_BConc_F, Mean_C) %>% 
  drop_na() %>% 
  dplyr::group_by(Type) %>% 
  dplyr::summarize(Corr_mean = round(cor(Mean_C, Mean_BConc_F), digits = 2), Corr_max = round(cor(Mean_C, Max_BConc_F), digits = 2), Corr_min = round(cor(Mean_C, Min_BConc_F), digits = 2))

#Get count by group
expressions_analysis_nofun %>% 
  dplyr::select(Expression, Type, Mean_BConc_F, Max_BConc_F, Min_BConc_F, Mean_C) %>% 
  drop_na() %>% 
  dplyr::group_by(Type) %>%
  count()

```

```{r plot relationships of content words and full expression}
#Get data frame for plot and change to long format
conc_compare_plot_nof <- expressions_analysis_nofun %>% 
  dplyr::select(Expression, Type, Mean_BConc_F, Max_BConc_F, Min_BConc_F, Mean_C) %>% 
  drop_na() %>% 
  pivot_longer(cols = c("Mean_BConc_F", "Max_BConc_F", "Min_BConc_F"), names_to = "Ind_Words", values_to = "Mean_Conc_Words")

#Create labels for subplots
Ind_Words.labs <- c("Maximum Concreteness", "Mean Concreteness", "Minimum Concreteness")
names(Ind_Words.labs) <- c("Max_BConc_F", "Mean_BConc_F", "Min_BConc_F")

Type.labs <- c("Idiom/Fixed expression", "Compound noun", "Particle verb")
names(Type.labs) <- c("Idiom/Fixed expression", "Compound noun", "Particle verb")

#Plot relationships
ggplot(conc_compare_plot_nof, aes(Mean_C, Mean_Conc_Words)) + geom_point(size = 0.25, colour = "black", alpha = 0.15) + geom_smooth(method = lm, lwd = 1, colour = 4) + facet_grid(Ind_Words ~ Type, labeller = labeller(Ind_Words = Ind_Words.labs, Type = Type.labs)) + xlab ("Concreteness of Expression") + ylab("Concreteness of Individual Content Words") + theme(text = element_text(size = 20))

#Save file
ggsave(filename = file.path(figures_out, "Figure3_02.25.2022.png"), width = 12, height = 12)
```

